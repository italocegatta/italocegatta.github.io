<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Web Scraping on Ítalo Cegatta</title>
    <link>/categories/web-scraping/</link>
    <description>Recent content in Web Scraping on Ítalo Cegatta</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <lastBuildDate>Fri, 16 Jun 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/web-scraping/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Web scraping: dados de páginas da internet na palma da sua mão</title>
      <link>/web-scraping-dados-de-paginas-da-internet-na-palma-da-sua-mao/</link>
      <pubDate>Fri, 16 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/web-scraping-dados-de-paginas-da-internet-na-palma-da-sua-mao/</guid>
      <description>Você já precisou copiar na mão uma informação de texto, valor ou tabela de uma pagina web? Pelo menos no meu trabalho isto é muito comum. Por mais que os dados estejam lá site, eles nunca estão disponíveis todos juntos e no formato que queremos, parece que é de sacanagem. Diante disto, o objetivo deste post é mostrar como podemos utilizar o R para coletar dados de uma página web e esquecer o famooooso ctrl+c/ctrl+v.</description>
    </item>
    
  </channel>
</rss>